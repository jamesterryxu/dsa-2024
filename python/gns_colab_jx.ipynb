{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Y0EtE29uWUv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b525ede6-ac47-4774-b548-3a8205e6a33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.3.1+cu121 with cuda 12.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import math\n",
        "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "# Optional dependencies:\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ],
      "metadata": {
        "id": "EGdduR5yDsAO",
        "outputId": "9d797cbf-882d-46af-c5b9-609d755de7f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt23cu121)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt23cu121)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt23cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import MessagePassing, radius_graph\n",
        "from torch_geometric.utils import add_self_loops\n",
        "import torch_cluster\n",
        "import torch_scatter\n",
        "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")\n",
        "\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "os.makedirs('train_log', exist_ok=True)\n",
        "os.makedirs('rollouts', exist_ok=True)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-sYTZtP6DoL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b787a0-b3eb-439d-c367-cfb39c6594cd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.3.1+cu121 with cuda 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrY6KUfsXIIv",
        "outputId": "8dc6eccd-4970-4f64-fdb6-b287f61fb730"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start coding with numpy==1.23.1\n",
        "# !pip uninstall numpy -y\n",
        "# !pip install numpy==1.23.1"
      ],
      "metadata": {
        "id": "I8VjFiaeXU0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "OTaYxnvVIEid"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tree\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EWoR2idfY7bd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "3N6qVuPkY-zg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, create a function to generate a graph from raw data."
      ],
      "metadata": {
        "id": "LSLBKX1KBYxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import radius_graph\n",
        "\n",
        "def create_gnn_graph(coordinates, metadata):\n",
        "    \"\"\"\n",
        "    Create a graph data object for a GNN model.\n",
        "\n",
        "    Args:\n",
        "    - coordinates (list of tuples): A list of 2D coordinates for each node.\n",
        "    - E_initial (float): The initial value for the edge attribute.\n",
        "\n",
        "    Returns:\n",
        "    - data (Data): A PyG Data object representing the graph.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert coordinates to tensor\n",
        "    node_features = torch.tensor(coordinates, dtype=torch.float)\n",
        "\n",
        "    # Add the load as a node attribute\n",
        "    load = torch.rand(node_features.size(0), 1) * metadata[\"P_initial\"]\n",
        "    dist_boundary = torch.norm(node_features - torch.tensor([[0, 0]], dtype=torch.float), dim=1).unsqueeze(1)\n",
        "\n",
        "    # Create edges\n",
        "    num_nodes = len(coordinates)\n",
        "    edge_index = radius_graph(node_features, r=metadata[\"default_connectivity_radius\"], loop=False)\n",
        "\n",
        "    # Calculate edge attributes (e.g., Euclidean distance)\n",
        "    distance = torch.norm(node_features[edge_index[0]] - node_features[edge_index[1]], dim=1).unsqueeze(1)\n",
        "    # Calculate displacement as vector at each edge\n",
        "    displacement = (node_features[edge_index[1]] - node_features[edge_index[0]])\n",
        "\n",
        "    # Convert E_initial to a PyTorch tensor\n",
        "    E_initial = torch.tensor(metadata[\"E_initial\"], dtype=torch.float)\n",
        "    # Correctly generate a tensor with random values uniformly distributed between 0 and 1, then scale by E_initial\n",
        "    E_edge = torch.rand(edge_index.size(1), 1) * E_initial\n",
        "\n",
        "    # Now, both tensors have shape [number_of_edges, 1] and can be concatenated\n",
        "    edge_attr = torch.cat([distance, displacement, E_edge], dim=1)\n",
        "\n",
        "    # Create a graph data object\n",
        "    graph_data = Data(pos=node_features, edge_index=edge_index, edge_attr=edge_attr, node_attr=load)\n",
        "\n",
        "    return graph_data\n",
        "\n",
        "# Example usage\n",
        "metadata = {\"default_connectivity_radius\": 1.6, \"E_initial\": 10, \"P_initial\": 0}\n",
        "coordinates = [(0.5, 0), (1.5, 0), (2.5, 0), (3.5, 0), (4.5, 0)]\n",
        "graph_data = create_gnn_graph(coordinates, metadata)\n",
        "\n",
        "graph = to_networkx(graph_data)\n",
        "nx.draw(graph, with_labels=True)\n",
        "plt.show()\n",
        "\n",
        "print(graph_data.edge_attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "o3j7BB9KBPX3",
        "outputId": "fca22234-9115-400c-d4b3-e7d093a6a7cc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0000, -1.0000,  0.0000,  0.4709],\n",
            "        [ 1.0000,  1.0000,  0.0000,  5.9367],\n",
            "        [ 1.0000, -1.0000,  0.0000,  0.1412],\n",
            "        [ 1.0000,  1.0000,  0.0000,  4.0954],\n",
            "        [ 1.0000, -1.0000,  0.0000,  5.8849],\n",
            "        [ 1.0000,  1.0000,  0.0000,  9.3113],\n",
            "        [ 1.0000, -1.0000,  0.0000,  2.9669],\n",
            "        [ 1.0000,  1.0000,  0.0000,  9.0533]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check version of cuda\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw_n4CbFDC3C",
        "outputId": "ebb39e5b-6e27-4fd7-b970-bdbe29686d1c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n",
            "12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP class function"
      ],
      "metadata": {
        "id": "1VM7XVk9Fohd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class MLP(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Create a simple MLP\n",
        "#     \"\"\"\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         input_size,\n",
        "#         layer_sizes,\n",
        "#         output_size=None,\n",
        "#         output_activation=torch.nn.Identity,\n",
        "#         activation=torch.nn.ReLU,\n",
        "#         layernorm=True\n",
        "#     ):\n",
        "#         super(MLP, self).__init__()\n",
        "#         sizes = [input_size] + layer_sizes\n",
        "#         if output_size is not None:\n",
        "#             sizes.append(output_size)\n",
        "#         layers = []\n",
        "#         for i in range(len(sizes) - 1):\n",
        "#             layers.append(torch.nn.Linear(sizes[i], sizes[i + 1]))\n",
        "#             if layernorm and i < len(sizes) - 2:\n",
        "#                 layers.append(torch.nn.LayerNorm(sizes[i + 1]))\n",
        "#             if i < len(sizes) - 2:\n",
        "#                 layers.append(activation())\n",
        "#             else:\n",
        "#                 layers.append(output_activation())\n",
        "#         self.model = torch.nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.model(x)"
      ],
      "metadata": {
        "id": "gFMVulxFC9wp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Create a simple MLP\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        layer_sizes,\n",
        "        output_size=None,\n",
        "        output_activation=torch.nn.Identity,\n",
        "        activation=torch.nn.ReLU\n",
        "    ):\n",
        "        super(MLP, self).__init__()\n",
        "        sizes = [input_size] + layer_sizes\n",
        "        if output_size is not None:\n",
        "            sizes.append(output_size)\n",
        "        layers = []\n",
        "        for i in range(len(sizes) - 1):\n",
        "            if (i < len(sizes) - 2):\n",
        "                act = activation\n",
        "            else:\n",
        "                act = output_activation\n",
        "            layers += [torch.nn.Linear(sizes[i], sizes[i + 1]), act()]\n",
        "        self.model = torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "FIFg__aOhuyX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "Vv1aF3njFqhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in, # same shape as the data vertices (nodes) WARNING\n",
        "        node_out, # shape for the processor block\n",
        "        edge_in, # same shape as the data edges (elements)\n",
        "        edge_out, # shape for the processor block\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Implement the encoder.\n",
        "        # Hint: The node_fn and edge_fn are of the same structure, which is a MLP layer followed by a layer norm\n",
        "        ############################################################################\n",
        "        self.node_fn = nn.Sequential(*[MLP(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out),\n",
        "            nn.LayerNorm(node_out)])\n",
        "        self.edge_fn = nn.Sequential(*[MLP(edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out),\n",
        "            nn.LayerNorm(edge_out)])\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, e_features): # global_features\n",
        "        '''\n",
        "        x: (E, node_in)\n",
        "        edge_index: (2, E)\n",
        "        e_features: (E, edge_in)\n",
        "        '''\n",
        "        return self.node_fn(x), self.edge_fn(e_features)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in, # directly from the processor\n",
        "        node_out, # this shape needs to be (num_nodes of real problem x 2). The first column should be u, the second should be p.\n",
        "        edge_in, # directly from the processor\n",
        "        edge_out, # this shape needs to be (num_elements of real problem x 1). The first column should be ei.\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        ############################################################################\n",
        "        # Implement the decoder.\n",
        "        # The decoder outputs both node and edge information.\n",
        "        ############################################################################\n",
        "        self.node_fn = MLP(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out)\n",
        "        self.edge_fn = MLP(edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out)\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, e_features):\n",
        "        '''\n",
        "        x: (E, node_in)\n",
        "        e_features: (E, edge_in)\n",
        "        '''\n",
        "        ############################################################################\n",
        "        # Implement the forward pass.\n",
        "        ############################################################################\n",
        "        return self.node_fn(x), self.edge_fn(e_features)\n",
        "        ############################################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "iM-Fa5kC_Vtq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity check the encoder decoder implementation with the node AND edge outputs"
      ],
      "metadata": {
        "id": "q4_Qn_eRZhX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message passing"
      ],
      "metadata": {
        "id": "4qy55GmEF-Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionNetwork(MessagePassing):\n",
        "    # Inherits from pyg.MessagePassing. Much faster!\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_fn,\n",
        "        edge_fn,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.node_fn = node_fn\n",
        "        self.edge_fn = edge_fn\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        x_updated, e_updated = self.propagate(edge_index=edge_index, x=x, e_features=e_features)\n",
        "        return x_updated, e_updated\n",
        "\n",
        "    def message(self, edge_index, x_i, x_j, e_features):\n",
        "        message = torch.cat([x_i, x_j, e_features], dim=-1)\n",
        "        message = self.edge_fn(message)\n",
        "        return message\n",
        "\n",
        "    def aggregate(self, messages, index, dim_size=None):\n",
        "        out = torch_scatter.scatter(messages, index, dim=self.node_dim, dim_size=dim_size, reduce=\"sum\")\n",
        "        return (messages, out)\n",
        "\n",
        "    def update(self, aggr_out, x, e_features):\n",
        "        message, aggr = aggr_out\n",
        "        x_updated = torch.cat([aggr, x], dim=-1)\n",
        "        x_updated = self.node_fn(x_updated)\n",
        "        return x_updated+x, e_features+message"
      ],
      "metadata": {
        "id": "1s865OW1F9qX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The processer has $M$ layers of InteractionNetworks"
      ],
      "metadata": {
        "id": "ssnOxwogZx73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Processor(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Processor, self).__init__(aggr='max')\n",
        "        self.gnn_stacks = nn.ModuleList([\n",
        "            InteractionNetwork(\n",
        "                node_fn = nn.Sequential(*[MLP(node_in+edge_out, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out),\n",
        "                nn.LayerNorm(node_out)]),\n",
        "                edge_fn = nn.Sequential(*[MLP(node_in+node_in+edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out),\n",
        "                nn.LayerNorm(edge_out)])\n",
        "            ) for _ in range(num_message_passing_steps)])\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        for gnn in self.gnn_stacks:\n",
        "            x, e_features = gnn(x, edge_index, e_features)\n",
        "        return x, e_features"
      ],
      "metadata": {
        "id": "8lQlVqBlT8G2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the encoder, processor, and decoder into a single network."
      ],
      "metadata": {
        "id": "6dG5XLWUZ4Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodeProcessDecode(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        latent_dim,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(EncodeProcessDecode, self).__init__()\n",
        "        ############################################################################\n",
        "        # Implementation of the encoder, processor, and decoder\n",
        "        ############################################################################\n",
        "        self._encoder = Encoder(\n",
        "            node_in=node_in,\n",
        "            node_out=latent_dim,\n",
        "            edge_in=edge_in,\n",
        "            edge_out=latent_dim,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "        self._processor = Processor(\n",
        "            node_in=latent_dim,\n",
        "            node_out=latent_dim,\n",
        "            edge_in=latent_dim,\n",
        "            edge_out=latent_dim,\n",
        "            num_message_passing_steps=num_message_passing_steps,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "        self._decoder = Decoder(\n",
        "            node_in=latent_dim,\n",
        "            node_out=node_out,\n",
        "            edge_in=latent_dim,\n",
        "            edge_out=edge_out,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        ''' forward pass of the architecture\n",
        "          x: (E, node_in) -> e.g., (5, 3) if there are 5 nodes each with 3 features\n",
        "          edge_index: (2, num_edges) -> e.g., (2, 4) if there are 4 edges\n",
        "          e_features: (E, edge_in) -> e.g., (5, 4) if there are 5 edges each with 4 features\n",
        "        '''\n",
        "        ############################################################################\n",
        "        # TODO: implementation of making a forward pass through the encoder,\n",
        "        # processor, and decoder blocks\n",
        "        ############################################################################\n",
        "        x, e_features = self._encoder(x, e_features)\n",
        "        x, e_features = self._processor(x, edge_index, e_features)\n",
        "        node_decoded, edge_decoded = self._decoder(x, e_features)\n",
        "        return node_decoded, edge_decoded\n",
        "        ############################################################################\n"
      ],
      "metadata": {
        "id": "nbmwx-L_Z2-Z"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simulator imports the training trajectories. For the static case, it is just a single 1-D array of values that are position, $EI$, $u$, $p$. We put these into the graph."
      ],
      "metadata": {
        "id": "qXSUG_peZ_eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Simulator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes,\n",
        "        num_edges,\n",
        "        node_dimension,\n",
        "        edge_dimension,\n",
        "        node_in,\n",
        "        edge_in,\n",
        "        latent_dim, # this is what we choose for the size of the network\n",
        "        num_message_passing_steps, # this is M\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "        connectivity_radius,\n",
        "        # device='cpu',\n",
        "    ):\n",
        "        super(Simulator, self).__init__()\n",
        "        self._connectivity_radius = connectivity_radius\n",
        "\n",
        "        self._encode_process_decode = EncodeProcessDecode(\n",
        "            node_in=node_in,\n",
        "            node_out=node_dimension,\n",
        "            edge_in=edge_in,\n",
        "            edge_out=edge_dimension,\n",
        "            latent_dim=latent_dim,\n",
        "            num_message_passing_steps=num_message_passing_steps,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "        # self._device = device\n",
        "\n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    def _create_gnn_graph(self, coordinates):\n",
        "        \"\"\"\n",
        "        Create a graph data object for a GNN model.\n",
        "\n",
        "        Args:\n",
        "        - coordinates (list of tuples): A list of 2D coordinates for each node.\n",
        "\n",
        "        Returns:\n",
        "        - data (Data): A PyG Data object representing the graph, with edge and node features purley from the coordinates\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert coordinates to tensor\n",
        "        pos = torch.tensor(coordinates, dtype=torch.float)\n",
        "\n",
        "        # Concat node features and load\n",
        "        node_features = torch.cat([pos], dim=1)\n",
        "        # Create edges\n",
        "        num_nodes = len(coordinates)\n",
        "        edge_index = radius_graph(pos, r=self._connectivity_radius, loop=False)\n",
        "        # Calculate edge attributes (e.g., Euclidean distance)\n",
        "        distance = torch.norm(pos[edge_index[0]] - pos[edge_index[1]], dim=1).unsqueeze(1)\n",
        "        # Calculate displacement as vector at each edge\n",
        "        displacement = (pos[edge_index[1]] - pos[edge_index[0]])\n",
        "\n",
        "        edge_attr = torch.cat([distance, displacement], dim=1)\n",
        "        # Create a graph data object\n",
        "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "        return node_features,edge_index, edge_attr\n",
        "\n",
        "    def _decoder_post_processor(self, node_decoded, edge_decoded):\n",
        "      ''' TODO: We want to use the decoded edges and features to feed into the next iteration of gradient step\n",
        "      '''\n",
        "      #         edge_decoded = edge_attr = torch.cat([distance, displacement, E_edge], dim=1)\n",
        "      #         node_decoded = node_features = torch.cat([pos, load], dim=1)\n",
        "      # extract the nodal information\n",
        "      u = node_decoded[:,0] # deflection at each node, (num_nodes x 1), one deflection value in meters for each node\n",
        "      # p = node_decoded[:,1] # force applied at each node, (num_nodes x 1), one force magnitude value in meters for each node\n",
        "\n",
        "      # ei = edge_decoded[:,0] # flexural rigidity for each edge, (num_edges x 1), one value for flexural rigidity\n",
        "\n",
        "      return u#,p,ei\n",
        "\n",
        "    def predict_nodes_edges(self, coordinates):\n",
        "      ''' TODO: Change this to predict the new features of u, EI, and p\n",
        "\n",
        "      '''\n",
        "      node_features, edge_index, e_features = self._create_gnn_graph(coordinates)\n",
        "      node_decoded, edge_decoded = self._encode_process_decode(node_features, edge_index, e_features)\n",
        "      u = self._decoder_post_processor(node_decoded, edge_decoded)\n",
        "\n",
        "      # u,p,ei = self._decoder_post_processor(node_decoded, edge_decoded)\n",
        "      return u#,p,ei  # to be used in loss calculation\n",
        "\n"
      ],
      "metadata": {
        "id": "Hh-PA6PxaL5a"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding the training function"
      ],
      "metadata": {
        "id": "qu4-Iynmtu0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(lr, epoch, simulator, x_data, y_data):\n",
        "  ''' TODO: Implement the training loop.\n",
        "    Args:\n",
        "      simulator: the simulator model\n",
        "      x_data: our features\n",
        "      y_data: our labels\n",
        "  '''\n",
        "  loss_fn = torch.nn.MSELoss() # pure data loss for now\n",
        "  optimizer = torch.optim.Adam(simulator.parameters(), lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1 ** (1 / 5e6))\n",
        "\n",
        "  # recording loss curve\n",
        "  train_loss_list = []\n",
        "  pred_history_list = []\n",
        "  total_step = 0\n",
        "\n",
        "  # first use initial guess of data\n",
        "  data = x_data\n",
        "\n",
        "  for i in range(epoch):\n",
        "      simulator.train()\n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      pred = simulator.predict_nodes_edges(data)\n",
        "      loss_data = loss_fn(pred, y_data)\n",
        "      loss_data.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      print({\"data loss\": loss_data.item(), \"lr\": optimizer.param_groups[0][\"lr\"]})\n",
        "      total_step += 1\n",
        "\n",
        "      train_loss_list.append((total_step, loss_data.item()))\n",
        "      pred_history_list.append(pred)\n",
        "\n",
        "  return train_loss_list, pred_history_list # return loss and prediction history"
      ],
      "metadata": {
        "id": "9UBjHWyMupqm"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3l_QDlIwrb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11mG-J06wrwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time to train"
      ],
      "metadata": {
        "id": "_8VUdp9_wxCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test out one data set"
      ],
      "metadata": {
        "id": "XobsVrOPeyfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "data_df = pd.read_csv(\"node-disp_l=10_n=100_p=1.csv\")\n",
        "data_df.head()\n",
        "data_x = torch.tensor(data_df['position'].values).view(100, 1)\n",
        "print(data_x.shape)\n",
        "data_y = torch.tensor(data_df['displacement']).view(100, 1)\n",
        "print(data_y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXMp0TwLw5sp",
        "outputId": "96496df7-9d9b-4ff3-a3ea-fa2499897c08"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1])\n",
            "torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VQqCYdttgWIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "simulator = Simulator(\n",
        "    num_nodes=100,\n",
        "    num_edges=99,\n",
        "    node_dimension=1,\n",
        "    edge_dimension=2,\n",
        "    node_in=1,\n",
        "    edge_in=2,\n",
        "    latent_dim=3,\n",
        "    num_message_passing_steps=2,\n",
        "    mlp_num_layers=2,\n",
        "    mlp_hidden_dim=3,\n",
        "    connectivity_radius=0.1011,\n",
        ")\n"
      ],
      "metadata": {
        "id": "4DTMaPB_b2-X"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGW5VuahjKVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, pred_history_list = train(lr = 1e-4,\n",
        "      epoch = 10,\n",
        "      simulator = simulator,\n",
        "      x_data = data_x,\n",
        "      y_data = data_y,\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "pYkjH1Puf5MD",
        "outputId": "50688373-49be-4688-830f-8e5778ae833e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-f768a57afd8b>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pos = torch.tensor(coordinates, dtype=torch.float)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found dtype Double but expected Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-9b1ba0a09bef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loss_list, pred_history_list = train(lr = 1e-4,\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-7ca8f7d2c68e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, epoch, simulator, x_data, y_data)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_nodes_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mloss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mloss_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mDxbvtUVe3NZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}