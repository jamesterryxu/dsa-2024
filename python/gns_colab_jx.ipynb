{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y0EtE29uWUv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09547a23-4b80-4f52-fbb2-e137911419f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.3.1+cu121 with cuda 12.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import math\n",
        "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "# Optional dependencies:\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ],
      "metadata": {
        "id": "EGdduR5yDsAO",
        "outputId": "fd73ee30-3e8f-45a1-aee2-8d0543fe2f06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/pyg_lib-0.4.0%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.1/947.1 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt23cu121 torch_cluster-1.6.3+pt23cu121 torch_scatter-2.1.2+pt23cu121 torch_sparse-0.6.18+pt23cu121 torch_spline_conv-1.2.2+pt23cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import MessagePassing, radius_graph\n",
        "from torch_geometric.utils import add_self_loops\n",
        "import torch_cluster\n",
        "import torch_scatter\n",
        "print(f\"PyTorch has version {torch.__version__} with cuda {torch.version.cuda}\")\n",
        "\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "os.makedirs('train_log', exist_ok=True)\n",
        "os.makedirs('rollouts', exist_ok=True)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-sYTZtP6DoL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52389a82-8794-4bab-fc7d-b46b5b7e140d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.3.1+cu121 with cuda 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrY6KUfsXIIv",
        "outputId": "dfa8e580-8f46-4902-a956-1c55fea683f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start coding with numpy==1.23.1\n",
        "# !pip uninstall numpy -y\n",
        "# !pip install numpy==1.23.1"
      ],
      "metadata": {
        "id": "I8VjFiaeXU0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "OTaYxnvVIEid"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tree\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EWoR2idfY7bd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "3N6qVuPkY-zg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, create a function to generate a graph from raw data."
      ],
      "metadata": {
        "id": "LSLBKX1KBYxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import radius_graph\n",
        "\n",
        "def create_gnn_graph(coordinates, metadata):\n",
        "    \"\"\"\n",
        "    Create a graph data object for a GNN model.\n",
        "\n",
        "    Args:\n",
        "    - coordinates (list of tuples): A list of 2D coordinates for each node.\n",
        "    - E_initial (float): The initial value for the edge attribute.\n",
        "\n",
        "    Returns:\n",
        "    - data (Data): A PyG Data object representing the graph.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert coordinates to tensor\n",
        "    node_features = torch.tensor(coordinates, dtype=torch.float)\n",
        "\n",
        "    # Add the load as a node attribute\n",
        "    load = torch.rand(node_features.size(0), 1) * metadata[\"P_initial\"]\n",
        "    dist_boundary = torch.norm(node_features - torch.tensor([[0, 0]], dtype=torch.float), dim=1).unsqueeze(1)\n",
        "\n",
        "    # Create edges\n",
        "    num_nodes = len(coordinates)\n",
        "    edge_index = radius_graph(node_features, r=metadata[\"default_connectivity_radius\"], loop=False)\n",
        "\n",
        "    # Calculate edge attributes (e.g., Euclidean distance)\n",
        "    distance = torch.norm(node_features[edge_index[0]] - node_features[edge_index[1]], dim=1).unsqueeze(1)\n",
        "    # Calculate displacement as vector at each edge\n",
        "    displacement = (node_features[edge_index[1]] - node_features[edge_index[0]])\n",
        "\n",
        "    # Convert E_initial to a PyTorch tensor\n",
        "    E_initial = torch.tensor(metadata[\"E_initial\"], dtype=torch.float)\n",
        "    # Correctly generate a tensor with random values uniformly distributed between 0 and 1, then scale by E_initial\n",
        "    E_edge = torch.rand(edge_index.size(1), 1) * E_initial\n",
        "\n",
        "    # Now, both tensors have shape [number_of_edges, 1] and can be concatenated\n",
        "    edge_attr = torch.cat([distance, displacement, E_edge], dim=1)\n",
        "\n",
        "    # Create a graph data object\n",
        "    graph_data = Data(pos=node_features, edge_index=edge_index, edge_attr=edge_attr, node_attr=load)\n",
        "\n",
        "    return graph_data\n",
        "\n",
        "# Example usage\n",
        "metadata = {\"default_connectivity_radius\": 1.6, \"E_initial\": 10, \"P_initial\": 0}\n",
        "coordinates = [(0.5, 0), (1.5, 0), (2.5, 0), (3.5, 0), (4.5, 0)]\n",
        "graph_data = create_gnn_graph(coordinates, metadata)\n",
        "\n",
        "graph = to_networkx(graph_data)\n",
        "nx.draw(graph, with_labels=True)\n",
        "plt.show()\n",
        "\n",
        "print(graph_data.edge_attr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "o3j7BB9KBPX3",
        "outputId": "796db2ff-b49e-4004-9372-768a7d7b1575"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0000, -1.0000,  0.0000,  7.2469],\n",
            "        [ 1.0000,  1.0000,  0.0000,  5.1847],\n",
            "        [ 1.0000, -1.0000,  0.0000,  5.1998],\n",
            "        [ 1.0000,  1.0000,  0.0000,  8.2049],\n",
            "        [ 1.0000, -1.0000,  0.0000,  1.7772],\n",
            "        [ 1.0000,  1.0000,  0.0000,  5.9624],\n",
            "        [ 1.0000, -1.0000,  0.0000,  4.6262],\n",
            "        [ 1.0000,  1.0000,  0.0000,  2.6828]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check version of cuda\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw_n4CbFDC3C",
        "outputId": "7b2cd1ff-ae3f-48cc-c7c9-869762fefa36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n",
            "12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP class function"
      ],
      "metadata": {
        "id": "1VM7XVk9Fohd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class MLP(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Create a simple MLP\n",
        "#     \"\"\"\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         input_size,\n",
        "#         layer_sizes,\n",
        "#         output_size=None,\n",
        "#         output_activation=torch.nn.Identity,\n",
        "#         activation=torch.nn.ReLU,\n",
        "#         layernorm=True\n",
        "#     ):\n",
        "#         super(MLP, self).__init__()\n",
        "#         sizes = [input_size] + layer_sizes\n",
        "#         if output_size is not None:\n",
        "#             sizes.append(output_size)\n",
        "#         layers = []\n",
        "#         for i in range(len(sizes) - 1):\n",
        "#             layers.append(torch.nn.Linear(sizes[i], sizes[i + 1]))\n",
        "#             if layernorm and i < len(sizes) - 2:\n",
        "#                 layers.append(torch.nn.LayerNorm(sizes[i + 1]))\n",
        "#             if i < len(sizes) - 2:\n",
        "#                 layers.append(activation())\n",
        "#             else:\n",
        "#                 layers.append(output_activation())\n",
        "#         self.model = torch.nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.model(x)"
      ],
      "metadata": {
        "id": "gFMVulxFC9wp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Create a simple MLP\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        layer_sizes,\n",
        "        output_size=None,\n",
        "        output_activation=torch.nn.Identity,\n",
        "        activation=torch.nn.ReLU\n",
        "    ):\n",
        "        super(MLP, self).__init__()\n",
        "        sizes = [input_size] + layer_sizes\n",
        "        if output_size is not None:\n",
        "            sizes.append(output_size)\n",
        "        layers = []\n",
        "        for i in range(len(sizes) - 1):\n",
        "            if (i < len(sizes) - 2):\n",
        "                act = activation\n",
        "            else:\n",
        "                act = output_activation\n",
        "            layers += [torch.nn.Linear(sizes[i], sizes[i + 1]), act()]\n",
        "        self.model = torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "FIFg__aOhuyX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "Vv1aF3njFqhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in, # same shape as the data vertices (nodes) WARNING\n",
        "        node_out, # shape for the processor block\n",
        "        edge_in, # same shape as the data edges (elements)\n",
        "        edge_out, # shape for the processor block\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Implement the encoder.\n",
        "        # Hint: The node_fn and edge_fn are of the same structure, which is a MLP layer followed by a layer norm\n",
        "        ############################################################################\n",
        "        self.node_fn = nn.Sequential(*[MLP(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out),\n",
        "            nn.LayerNorm(node_out)])\n",
        "        self.edge_fn = nn.Sequential(*[MLP(edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out),\n",
        "            nn.LayerNorm(edge_out)])\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, e_features): # global_features\n",
        "        '''\n",
        "        x: (E, node_in)\n",
        "        edge_index: (2, E)\n",
        "        e_features: (E, edge_in)\n",
        "        '''\n",
        "        return self.node_fn(x), self.edge_fn(e_features)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in, # directly from the processor\n",
        "        node_out, # this shape needs to be (num_nodes of real problem x 2). The first column should be u, the second should be p.\n",
        "        edge_in, # directly from the processor\n",
        "        edge_out, # this shape needs to be (num_elements of real problem x 1). The first column should be ei.\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        ############################################################################\n",
        "        # Implement the decoder.\n",
        "        # The decoder outputs both node and edge information.\n",
        "        ############################################################################\n",
        "        self.node_fn = MLP(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out)\n",
        "        self.edge_fn = MLP(edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out)\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, e_features):\n",
        "        '''\n",
        "        x: (E, node_in)\n",
        "        e_features: (E, edge_in)\n",
        "        '''\n",
        "        ############################################################################\n",
        "        # Implement the forward pass.\n",
        "        ############################################################################\n",
        "        return self.node_fn(x), self.edge_fn(e_features)\n",
        "        ############################################################################\n",
        "\n"
      ],
      "metadata": {
        "id": "iM-Fa5kC_Vtq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity check the encoder decoder implementation with the node AND edge outputs"
      ],
      "metadata": {
        "id": "q4_Qn_eRZhX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message passing"
      ],
      "metadata": {
        "id": "4qy55GmEF-Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionNetwork(MessagePassing):\n",
        "    # Inherits from pyg.MessagePassing. Much faster!\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_fn,\n",
        "        edge_fn,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.node_fn = node_fn\n",
        "        self.edge_fn = edge_fn\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        x_updated, e_updated = self.propagate(edge_index=edge_index, x=x, e_features=e_features)\n",
        "        return x_updated, e_updated\n",
        "\n",
        "    def message(self, edge_index, x_i, x_j, e_features):\n",
        "        message = torch.cat([x_i, x_j, e_features], dim=-1)\n",
        "        message = self.edge_fn(message)\n",
        "        return message\n",
        "\n",
        "    def aggregate(self, messages, index, dim_size=None):\n",
        "        out = torch_scatter.scatter(messages, index, dim=self.node_dim, dim_size=dim_size, reduce=\"sum\")\n",
        "        return (messages, out)\n",
        "\n",
        "    def update(self, aggr_out, x, e_features):\n",
        "        message, aggr = aggr_out\n",
        "        x_updated = torch.cat([aggr, x], dim=-1)\n",
        "        x_updated = self.node_fn(x_updated)\n",
        "        return x_updated+x, e_features+message"
      ],
      "metadata": {
        "id": "1s865OW1F9qX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The processer has $M$ layers of InteractionNetworks"
      ],
      "metadata": {
        "id": "ssnOxwogZx73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Processor(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Processor, self).__init__(aggr='max')\n",
        "        self.gnn_stacks = nn.ModuleList([\n",
        "            InteractionNetwork(\n",
        "                node_fn = nn.Sequential(*[MLP(node_in+edge_out, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out),\n",
        "                nn.LayerNorm(node_out)]),\n",
        "                edge_fn = nn.Sequential(*[MLP(node_in+node_in+edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out),\n",
        "                nn.LayerNorm(edge_out)])\n",
        "            ) for _ in range(num_message_passing_steps)])\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        for gnn in self.gnn_stacks:\n",
        "            x, e_features = gnn(x, edge_index, e_features)\n",
        "        return x, e_features"
      ],
      "metadata": {
        "id": "8lQlVqBlT8G2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the encoder, processor, and decoder into a single network."
      ],
      "metadata": {
        "id": "6dG5XLWUZ4Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodeProcessDecode(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        latent_dim,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(EncodeProcessDecode, self).__init__()\n",
        "        ############################################################################\n",
        "        # Implementation of the encoder, processor, and decoder\n",
        "        ############################################################################\n",
        "        self._encoder = Encoder(\n",
        "            node_in=node_in,\n",
        "            node_out=latent_dim,\n",
        "            edge_in=edge_in,\n",
        "            edge_out=latent_dim,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "        self._processor = Processor(\n",
        "            node_in=latent_dim,\n",
        "            node_out=latent_dim,\n",
        "            edge_in=latent_dim,\n",
        "            edge_out=latent_dim,\n",
        "            num_message_passing_steps=num_message_passing_steps,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "        self._decoder = Decoder(\n",
        "            node_in=latent_dim,\n",
        "            node_out=node_out,\n",
        "            edge_in=latent_dim,\n",
        "            edge_out=edge_out,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "        ############################################################################\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        ''' forward pass of the architecture\n",
        "          x: (E, node_in) -> e.g., (5, 3) if there are 5 nodes each with 3 features\n",
        "          edge_index: (2, num_edges) -> e.g., (2, 4) if there are 4 edges\n",
        "          e_features: (E, edge_in) -> e.g., (5, 4) if there are 5 edges each with 4 features\n",
        "        '''\n",
        "        ############################################################################\n",
        "        # TODO: implementation of making a forward pass through the encoder,\n",
        "        # processor, and decoder blocks\n",
        "        ############################################################################\n",
        "        x, e_features = self._encoder(x, e_features)\n",
        "        x, e_features = self._processor(x, edge_index, e_features)\n",
        "        node_decoded, edge_decoded = self._decoder(x, e_features)\n",
        "        return node_decoded, edge_decoded\n",
        "        ############################################################################\n"
      ],
      "metadata": {
        "id": "nbmwx-L_Z2-Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simulator imports the training trajectories. For the static case, it is just a single 1-D array of values that are position, $EI$, $u$, $p$. We put these into the graph."
      ],
      "metadata": {
        "id": "qXSUG_peZ_eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Simulator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes,\n",
        "        eldges,\n",
        "        node_dimension,\n",
        "        edge_dimension,\n",
        "        node_in,\n",
        "        edge_in,\n",
        "        latent_dim, # this is what we choose for the size of the network\n",
        "        num_message_passing_steps, # this is M\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "        connectivity_radius,\n",
        "        boundaries,\n",
        "        device='cuda',\n",
        "    ):\n",
        "        super(Simulator, self).__init__()\n",
        "        self._boundaries = boundaries\n",
        "        self._connectivity_radius = connectivity_radius\n",
        "\n",
        "        self._encode_process_decode = EncodeProcessDecode(\n",
        "            node_in=node_in,\n",
        "            node_out=node_dimension,\n",
        "            edge_in=edge_in,\n",
        "            edge_out=edge_dimension,\n",
        "            latent_dim=latent_dim,\n",
        "            num_message_passing_steps=num_message_passing_steps,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "        self._device = device\n",
        "\n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    def _create_gnn_graph(self, coordinates, metadata):\n",
        "        \"\"\"\n",
        "        Create a graph data object for a GNN model.\n",
        "\n",
        "        Args:\n",
        "        - coordinates (list of tuples): A list of 2D coordinates for each node.\n",
        "\n",
        "        Returns:\n",
        "        - data (Data): A PyG Data object representing the graph, with edge and node features purley from the coordinates\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert coordinates to tensor\n",
        "        pos = torch.tensor(coordinates, dtype=torch.float)\n",
        "\n",
        "        # Concat node features and load\n",
        "        node_features = torch.cat([pos], dim=1)\n",
        "        # Create edges\n",
        "        num_nodes = len(coordinates)\n",
        "        edge_index = radius_graph(pos, r=metadata[\"default_connectivity_radius\"], loop=False)\n",
        "        # Calculate edge attributes (e.g., Euclidean distance)\n",
        "        distance = torch.norm(pos[edge_index[0]] - pos[edge_index[1]], dim=1).unsqueeze(1)\n",
        "        # Calculate displacement as vector at each edge\n",
        "        displacement = (pos[edge_index[1]] - pos[edge_index[0]])\n",
        "\n",
        "        edge_attr = torch.cat([distance, displacement], dim=1)\n",
        "        # Create a graph data object\n",
        "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "        return node_features,edge_index, edge_attr\n",
        "\n",
        "    def _decoder_post_processor(self, node_decoded, edge_decoded)\n",
        "      ''' TODO: We want to use the decoded edges and features to feed into the next iteration of gradient step\n",
        "      '''\n",
        "      #         edge_decoded = edge_attr = torch.cat([distance, displacement, E_edge], dim=1)\n",
        "      #         node_decoded = node_features = torch.cat([pos, load], dim=1)\n",
        "      # extract the nodal information\n",
        "      u = node_decoded[:,0] # deflection at each node, (num_nodes x 1), one deflection value in meters for each node\n",
        "      p = node_decoded[:,1] # force applied at each node, (num_nodes x 1), one force magnitude value in meters for each node\n",
        "\n",
        "      ei = edge_decoded[:,0] # flexural rigidity for each edge, (num_edges x 1), one value for flexural rigidity\n",
        "\n",
        "      return u,p,ei\n",
        "\n",
        "    def predict_nodes_edges(self, coordinates, metadata):\n",
        "      ''' TODO: Change this to predict the new features of u, EI, and p\n",
        "\n",
        "      '''\n",
        "      node_features, edge_index, e_features = self._create_gnn_graph(coordinates,metadata)\n",
        "      node_decoded, edge_decoded = self._encode_process_decode(node_features, edge_index, e_features)\n",
        "      u,p,ei = self._decoder_postprocessor(node_decoded, edge_decoded)\n",
        "\n",
        "      return u,p,ei  # to be used in the next graph\n",
        "\n"
      ],
      "metadata": {
        "id": "Hh-PA6PxaL5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coding the training function"
      ],
      "metadata": {
        "id": "qu4-Iynmtu0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# params example\n",
        "# params = {\n",
        "#     \"epoch\": 100,\n",
        "#     \"batch_size\": 1,\n",
        "#     \"lr\": 1e-4,\n",
        "#     \"noise\": 3e-4\n",
        "# }"
      ],
      "metadata": {
        "id": "pFWnGT2StvtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(params, simulator, x_data, y_data):\n",
        "  ''' TODO: Implement the training loop.\n",
        "    Args:\n",
        "      simulator: the simulator model\n",
        "      x_data: our features\n",
        "      y_data: our labels\n",
        "  '''\n",
        "  loss_fn = torch.nn.MSELoss() # pure data loss for now\n",
        "  optimizer = torch.optim.Adam(simulator.parameters(), lr=params[\"lr\"])\n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1 ** (1 / 5e6))\n",
        "\n",
        "  # recording loss curve\n",
        "  train_loss_list = []\n",
        "  pred_history_list = []\n",
        "  total_step = 0\n",
        "\n",
        "  # first use initial guess of data\n",
        "  data = x_data\n",
        "\n",
        "  for i in range(params[\"epoch\"]):\n",
        "      simulator.train()\n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      pred = simulator(data)\n",
        "      loss_data = loss_fn(pred, y_data)\n",
        "      loss_data.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      print({\"data loss\": loss_data.item(), \"lr\": optimizer.param_groups[0][\"lr\"]})\n",
        "      total_step += 1\n",
        "\n",
        "      train_loss_list.append((total_step, loss_data.item()))\n",
        "      # # now update the x_data in the epoch loop!\n",
        "      # data = pred\n",
        "      # # replace the position with the original position\n",
        "\n",
        "          # # evaluation\n",
        "          # if total_step % params[\"eval_interval\"] == 0:\n",
        "          #     simulator.eval()\n",
        "          #     eval_loss, onestep_mse = oneStepMSE(simulator, valid_loader, valid_dataset.metadata, params[\"noise\"])\n",
        "          #     eval_loss_list.append((total_step, eval_loss))\n",
        "          #     onestep_mse_list.append((total_step, onestep_mse))\n",
        "          #     tqdm.write(f\"\\nEval: Loss: {eval_loss}, One Step MSE: {onestep_mse}\")\n",
        "          #     simulator.train()\n",
        "\n",
        "          # # save model\n",
        "          # if total_step % params[\"save_interval\"] == 0:\n",
        "          #     torch.save(\n",
        "          #         {\n",
        "          #             \"model\": simulator.state_dict(),\n",
        "          #             \"optimizer\": optimizer.state_dict(),\n",
        "          #             \"scheduler\": scheduler.state_dict(),\n",
        "          #         },\n",
        "          #         os.path.join(model_path, f\"checkpoint_{total_step}.pt\")\n",
        "          #     )\n",
        "  return train_loss_list, pred # return last prediction"
      ],
      "metadata": {
        "id": "9UBjHWyMupqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3l_QDlIwrb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11mG-J06wrwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training time"
      ],
      "metadata": {
        "id": "_8VUdp9_wxCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"epoch\": 10,\n",
        "    \"batch_size\": 1,\n",
        "    \"lr\": 1e-4,\n",
        "    \"noise\": 3e-4\n",
        "}"
      ],
      "metadata": {
        "id": "dpXBuJzEwryu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "train_dataset = ## TODO\"\n",
        "train_loader = pyg.loader.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True, pin_memory=True, num_workers=2)\n",
        "\n",
        "\n",
        "# build model\n",
        "simulator = LearnedSimulator()\n",
        "simulator = simulator.cuda()\n",
        "\n",
        "# train the model\n",
        "train_loss_list = train(params, simulator, train_loader)"
      ],
      "metadata": {
        "id": "WXMp0TwLw5sp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}